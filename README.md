# 评测开源大模型在专业领域下或抗越狱攻击的性能

LLM实践 - 任选其一即可

## 使用api
https://dmxapi.com/index.html#top  
注册并获取api的key

## 针对大语言模型的越狱攻击

### 任务说明
1. 获取api的key，填入main.py中，成功使用api调用大模型
2. 执行prompt.csv中每一条任务，并对结果进行截图记录
3. 对原始提示、伪装过的提示和伪装加对抗后缀的提示三种的结果进行分析
4. 对最后一条任务设计自己的提示文本，与其他同学重复率低


### 提交说明
提交完整的实验报告，系统归纳总结越狱提示词设计思路，并分析成功和失败的原因是什么。

## 评估大语言模型在专业领域下的表现

### 任务说明
1. 在5种专业领域共25个问题中评估5种LLMs，在不同prompt下的表现。
2. 评估LLM可通过人为检查/通过参考答案交给GPT4o等高级LLM来评判
3. 分析各模型的能力边界、缺陷和风险等，可尝试用LLM撰写分析报告
4. 报告中包含定量的实验结果
5. 提交报告和构造的评测数据集即可

### 任务举例
- 分类：计算机史、离散数学、程序设计、人工智能、计算机系统
- Prompt方式：直接询问（是什么）、选择题（ABCD）、指令（帮我写一份代码）等
- 评测答案：前两者可直接提供答案+解题思路（可选），后面则只能人为或高级LLM评估

